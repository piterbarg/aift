{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Automatic Implicit Function Theorem\n",
        "## Exact fit example\n",
        "This is the main notebook referenced and annotated in the paper\n",
        "> Dmitri Goloubentsev, Evgeny Lakshtanov, Vladimir V. Piterbarg (2021), Automatic Inverse Function Theorem"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xFH2D6lt6VD2"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from scipy.optimize import least_squares\n",
        "\n",
        "from autograd import grad, jacobian # pip install autograd\n",
        "import autograd.numpy as np   # Thinly-wrapped version of Numpy to fascilitate autograd calcs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N08P2Hcc6VD3"
      },
      "source": [
        "## Define the polynomial value function and the interpolator function\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h1l0iHe9464Y"
      },
      "source": [
        "\n",
        "In this section we set up the problem that we will apply AAD to.\n",
        "\n",
        "The function **spolyval(...)** gives the values of the 'stretched polynomial' at times **ts[n]** given the coefficients ***coefs*** and weights $w$.\n",
        "\n",
        "The 'stretched polynomial' function is a (somewhat contrived but simple) example of an interpolator that fits all the points but which interpolation scheme, and the shape of the function between knots, depends on the weights $w$.\n",
        "\n",
        "**spolyval(...)** corresponds to $\\Omega(c,x,w)$ in the paper."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eSiFOc9v6VD5"
      },
      "outputs": [],
      "source": [
        "\n",
        "def spolyval(coefs, ts, w):\n",
        "    '''\n",
        "    A 'stretched polynomial' function, a polynomial in wts,\n",
        "    where wts = w[0]*ts + w[1]*ts**2.\n",
        "    Wegiths w here control the shape of the function between knots.\n",
        "\n",
        "    coefs:  polynomial coefs\n",
        "    ts:     points where the function is evaluated\n",
        "    w:      weights to transform ts into wts\n",
        "    '''\n",
        "    tsw = w[0]*ts + w[1]*ts**2\n",
        "    val = 0.0\n",
        "    for n in range(len(coefs)):\n",
        "        val =  val + coefs[n] * tsw**n\n",
        "    return val\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a910BqyrNUds"
      },
      "source": [
        "We simulate a typical programming pattern where auxilliary variables such as $w$\n",
        "come wrapped in various helpers, etc. This is not strictly necessary in this code but will be used later to illustrate important points. \n",
        "\n",
        "From the point of view of the paper, the overall construction, i.e. the class constructor and the **PricingHelper.spolyval(...)** method correspond to $\\Omega(c,x,W(x))$ in the paper. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m2Ko1J6J464Z"
      },
      "outputs": [],
      "source": [
        "\n",
        "class PricingHelper:\n",
        "    def __init__(self, w):\n",
        "        self.w_ = w\n",
        "        self.updatable = False\n",
        "        # If w is none we link w's to xs's in a particular way \n",
        "        # to introduce the extra dependence of the result of spoly_interp \n",
        "        # on xs via w (admittedly, somewhat artificially). The actual update \n",
        "        # happens in the update(...) function that the clients are supposed \n",
        "        # to call when the xs are known.\n",
        "        if w is None:\n",
        "            self.updatable = True\n",
        "\n",
        "    def update(self, xs, ts):\n",
        "        '''\n",
        "        Update the weights depending on the inputs ts (not used \n",
        "        in this example) and xs.\n",
        "        '''\n",
        "        if self.updatable:\n",
        "            self.w_ = np.array([1.0, np.sum(xs**2)])\n",
        "     \n",
        "    def spolyval(self,c,ts):\n",
        "        return spolyval(c, ts, self.w_) \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tAglnKb9464a"
      },
      "source": [
        "Function **spoly_interp(...)** calculates the coefs by fitting spolyval to **ts,xs** and returns the value of **spolyval** at some other point **t**.\n",
        "Note how **w** is never seen inside the body of the function, all wrapped in **PricingHelper**.\n",
        "\n",
        "Executing **spoly_interp(...)** corresponds to computing the implicit function $C(x,w)$ from the paper."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aCGAGNMt464a"
      },
      "outputs": [],
      "source": [
        "\n",
        "def spoly_interp(xs, ts, t, pricing_helper):\n",
        "    '''\n",
        "    Fit a stretched polynomial to (ts,xs) and evaluate it at t\n",
        "    Here pricing_helper (via pricing_helper.w_) is defining \n",
        "    the interpolation between the knots. \n",
        "    '''\n",
        "    pricing_helper.update(xs,ts)\n",
        "    \n",
        "    def obj_f(c, x, pricing_helper = pricing_helper):\n",
        "        return pricing_helper.spolyval(c, ts) - x\n",
        "\n",
        "    x0 = np.zeros_like(ts)\n",
        "    res = least_squares(lambda c : obj_f(c, xs), x0)\n",
        "    c_fit = res.x\n",
        "    return pricing_helper.spolyval(c_fit, t)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YaW3J_6f464b"
      },
      "source": [
        "An example of applying **spoly_interp(...)**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "Sm7VufN96VD7",
        "outputId": "c20b4bd1-0753-4fcd-f7a7-55f2a36666e0"
      },
      "outputs": [],
      "source": [
        "# points we interpolate\n",
        "ts = np.array([0.,1,2,3,4])\n",
        "xs = np.array([2.,1,3,4,0])\n",
        "\n",
        "# the point at which we evaluate our interpolator\n",
        "t = 3.5 \n",
        "\n",
        "# We can try different values of w. 'None' is the default that triggers\n",
        "# the calculation w = w(x)\n",
        "# \n",
        "# w(xs) for the particular xs above is equal to [1.0,30.0] so \n",
        "# we can pass them directly and it will not affect the output value of \n",
        "# spoly_interp(...) but of course will affect the gradients\n",
        "\n",
        "# Uncomment one of these\n",
        "# w_to_use = None\n",
        "w_to_use = [1.0,30.0] \n",
        "\n",
        "# Set up the pricer helper\n",
        "pricing_helper = PricingHelper(w_to_use)\n",
        "\n",
        "# calculate the interpolated value\n",
        "v = spoly_interp(xs,ts,t, pricing_helper)\n",
        "print(f'value = {v}')\n",
        "\n",
        "# plot a graph to see what the interpolation function looks like\n",
        "t_fine = ts[0] + np.arange(101)/100*(ts[-1] - ts[0])\n",
        "v_fine = spoly_interp(xs,ts,t_fine, pricing_helper)\n",
        "plt.plot(t_fine, v_fine, '-', label = 'fitted interpolator')\n",
        "plt.plot(ts,xs,'o', label = 'interpolated points')\n",
        "plt.plot(t,v,'o',label = 'evaluation point')\n",
        "plt.legend(loc = 'best')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-IV8at1464d"
      },
      "source": [
        "Now calculate the gradients using bumping."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AMVV_9MN6VEC",
        "outputId": "5047f99e-50da-4d06-89bf-8b8bbbe0262a"
      },
      "outputs": [],
      "source": [
        "eps = 1e-5\n",
        "grad_bump = np.zeros_like(xs)\n",
        "for n in range(len(xs)):\n",
        "    x1 = xs.copy()\n",
        "    x1[n] += eps\n",
        "    grad_bump[n] = (spoly_interp(x1, ts, t, pricing_helper) - spoly_interp(xs, ts, t, pricing_helper))/eps\n",
        "np.set_printoptions(precision=3)\n",
        "print(f'gradients by bumping = {grad_bump}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pFxZggYV6VD9"
      },
      "source": [
        "## Try autograd on poly_interp, 'differentiating' through the solver\n",
        "`autograd` is a Python package that calculates the gradients at the same time as the values by overloading the Numpy operations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IkMiiSVY6VD9",
        "outputId": "a3ea8420-e38f-47fd-866a-00f4dcc539e9"
      },
      "outputs": [],
      "source": [
        "# this does not work as expected since least_squares is not \n",
        "# supported by autograd\n",
        "def spoly_interp_for_autograd(xs,ts,t):\n",
        "    return spoly_interp(xs,ts,t, pricing_helper)\n",
        "\n",
        "spi_grad = grad(spoly_interp_for_autograd)\n",
        "try:\n",
        "    print(spi_grad(ts,xs,t))\n",
        "except Exception as e:\n",
        "    print(f'Does not work, exception: {e}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNMAVk566VD-"
      },
      "source": [
        "## Modify spoly_interp to calculate the gradients to the inputs xs using the naive Implicit Function Theorem"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vm4blRPn464f"
      },
      "source": [
        "Extend PricingHelper to calculate the potential dw/dx\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8b0Q7TUY464f"
      },
      "outputs": [],
      "source": [
        "class PricingHelperIft(PricingHelper):\n",
        "    '''\n",
        "    We simulate a typical programming pattern where auxilliary variables such \n",
        "    as w come wrapped in various helpers, etc. This is not strictly necessary\n",
        "    in this code but will be used later to illustrate some points.\n",
        "    '''\n",
        "    def __init__(self, w):\n",
        "        super().__init__(w)\n",
        "    \n",
        "    def update(self, xs, ts):\n",
        "        super().update(xs,ts)\n",
        "\n",
        "        # Capture the gradients if w is in fact a function of x. We could call\n",
        "        # autograd here but choose to code this by hand for brevity.\n",
        "        if self.updatable:\n",
        "            self.dw_dx_ = np.vstack((np.zeros_like(xs), 2*xs))\n",
        "        else:\n",
        "            self.dw_dx_ = np.zeros((2,len(xs)))\n",
        "     "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XF2Ogoof464f"
      },
      "source": [
        "Modify **spoly_inter(...)** calling autograd when needed and implementing the IFT logic manually.\n",
        "\n",
        "The variable **c_fit** corresponds to $C(x,W(x))$ in the paper. Note that this driver should be aware of the variable $w$ to calculate **dobj_dw** i.e. $\\frac{\\partial \\Omega}{\\partial w}$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fLmgOEXE6VD-"
      },
      "outputs": [],
      "source": [
        "def spoly_interp_ift(xs, ts, t, pricing_helper):\n",
        "    '''\n",
        "    This is a modification of spoly_interp() that supports gradients via \n",
        "    Naive IFT. We use autograd and need to use manual gradient manipulations\n",
        "    to collect them all.\n",
        "    \n",
        "    The original function spoly_interp(...) fits a stretched polynomial to \n",
        "    (ts,xs) and evaluates it at t. Here pricing_helper (via pricing_helper.w_)\n",
        "    is defining the interpolation between knots.\n",
        "    '''\n",
        "\n",
        "    # Update the weights w and extract the relevant gradients\n",
        "    pricing_helper.update(xs,ts)\n",
        "    dw_dx = pricing_helper.dw_dx_\n",
        "\n",
        "    # The original objective function\n",
        "    def obj_f(c, x, pricing_helper = pricing_helper):\n",
        "        return pricing_helper.spolyval(c, ts) - x\n",
        "\n",
        "    # We need an unwrapped version of the objective function for autograd \n",
        "    # to be able to calculate dobj_dw below.\n",
        "    def obj_f_wrapper(c, x, w):\n",
        "        helper_ = PricingHelper(w)\n",
        "        return helper_.spolyval(c, ts) - x\n",
        "\n",
        "    x0 = np.zeros_like(ts)\n",
        "    res = least_squares(lambda c: obj_f(c,xs), x0)\n",
        "    \n",
        "    c_fit = res.x\n",
        "    v = pricing_helper.spolyval(c_fit, t)\n",
        "    # calc the gradients using IFT\n",
        "    dobj_dc = jacobian(obj_f, argnum = 0)(c_fit,xs)\n",
        "    dobj_dx = jacobian(obj_f, argnum = 1)(c_fit,xs)\n",
        "    dc_dx = -np.linalg.lstsq(dobj_dc,dobj_dx, rcond = None)[0]\n",
        "\n",
        "    # Calculate the gradient with respect to w. We need to keep adding\n",
        "    # these for all \"hidden\" variables that are used in obj_f\n",
        "    w = np.array(pricing_helper.w_.copy()) # a bit of a hoop here for autograd\n",
        "    dobj_dw = jacobian(obj_f_wrapper, argnum = 2)(c_fit,xs,w)   \n",
        "    \n",
        "    dc_dw = -np.linalg.lstsq(dobj_dc,dobj_dw, rcond = None)[0]\n",
        "    dc_dx += (dc_dw @ dw_dx)\n",
        "\n",
        "    dv_dc = grad(spolyval, argnum = 0)(c_fit, t, w)\n",
        "    dv_dx = dv_dc @ dc_dx\n",
        "\n",
        "    # need to add the dw_dx contribution to the final valuation as well\n",
        "    dv_dw = grad(spolyval, argnum = 2)(c_fit, t, w)\n",
        "    dv_dx += dv_dw @ dw_dx\n",
        "\n",
        "    return v, dv_dx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7F-Qx0N6464g"
      },
      "source": [
        "Calculate the gradients using naive IFT and compare to gradients by bumping calculated previously.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X0ZILyvV464g",
        "outputId": "dbc55604-bc0a-4ed3-d75a-f43c0dc2748b"
      },
      "outputs": [],
      "source": [
        "\n",
        "pricing_helper = PricingHelperIft(w_to_use)\n",
        "v_ift, grad_ift = spoly_interp_ift(xs,ts,t,pricing_helper)\n",
        "print(f'value = {v_ift}')\n",
        "print(f'gradients by ift = {grad_ift}')\n",
        "print(f'gradients by bmp = {grad_bump}')\n",
        "print(f'difference in gradients = {grad_ift - grad_bump}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_1lFEtYmt9a"
      },
      "source": [
        "## Calculate the gradients using AAD + Automatic IFT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QxqMZD6C464h"
      },
      "source": [
        "We implement the adjoints in **PricingHelper**. In a true AAD library these are generated automatically."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fDzFkNMp464h"
      },
      "outputs": [],
      "source": [
        "\n",
        "class PricingHelperAdj(PricingHelperIft):\n",
        "    def __init__(self, w):\n",
        "        super().__init__(w)\n",
        "     \n",
        "     \n",
        "    def spolyval_adj(self, c, ts, state_adj):\n",
        "        '''\n",
        "        Propagate the adjoints through spolyval. Normally generated \n",
        "        automatically by the AAD library.\n",
        "        '''\n",
        "        # make sure we accept a single float not just arrays\n",
        "        ts = np.atleast_1d(ts)\n",
        "        w=self.w_\n",
        "        nc = len(c)\n",
        "        nt = len(ts)\n",
        "\n",
        "        # Just like in spolyval\n",
        "        tsw = w[0]*ts + w[1]*ts**2\n",
        "\n",
        "        sp_bar = state_adj['sp_bar']\n",
        "\n",
        "        # the length of sp_bar changes depending on the number of outputs \n",
        "        # of spolyval which is given by nt, make sure we line up with the \n",
        "        # state_adj here\n",
        "        if len(sp_bar) != nt:\n",
        "            raise ValueError(f'sp_bar length {len(sp_bar)} is not equal to THE expected {nt}')\n",
        "\n",
        "        # Start the adjoints with whatever is in state_adj already -- \n",
        "        # this is important\n",
        "        c_bar = state_adj['c_bar']\n",
        "        w_bar = state_adj['w_bar']\n",
        "\n",
        "        # Loop over the length of the output of spolyval\n",
        "        for i in range(nt):\n",
        "\n",
        "            for n in range(nc):\n",
        "                # accumulate adjoints to coefs\n",
        "                c_bar[n] += tsw[i]**n * sp_bar[i]\n",
        "                \n",
        "                # Zero-order term has no sensitivity to w's\n",
        "                if n==0: \n",
        "                  continue\n",
        "\n",
        "                # accumulate adjoints for w's\n",
        "                w_bar[0] += c[n] * n * tsw[i]**(n-1) * ts[i] * sp_bar[i]\n",
        "                w_bar[1] += c[n] * n * tsw[i]**(n-1) * ts[i]**2 * sp_bar[i]\n",
        "\n",
        "        # put adjoints back in the state_adj\n",
        "        state_adj['c_bar'] = c_bar\n",
        "        state_adj['w_bar'] = w_bar"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jOGAYid8464h"
      },
      "source": [
        "Initialize the state for the adjoints."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pIAvFwSFznDs"
      },
      "outputs": [],
      "source": [
        "def init_state_adj(ncoefs):\n",
        "    '''\n",
        "    Initialize state_adj. This will be done by the AAD library.\n",
        "    '''\n",
        "    state_adj = {\n",
        "        'sp_bar': np.array([1]),    \n",
        "        'c_bar' : np.zeros(ncoefs),\n",
        "        'x_bar': np.zeros(ncoefs),\n",
        "        'w_bar' : np.zeros(2),\n",
        "        'f_bar': np.zeros(ncoefs),\n",
        "    }\n",
        "\n",
        "    return state_adj\n",
        "  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0pQFONj9464h"
      },
      "source": [
        "Adjoints for the objective function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ykyBh0CX464i"
      },
      "outputs": [],
      "source": [
        "def obj_f_adj(c, ts, x, helper, state_adj):\n",
        "    '''\n",
        "    Propagate adjoints through obj_f -- done by the AAD library\n",
        "    '''\n",
        "    f_bar = state_adj['f_bar']\n",
        "    x_bar = state_adj['x_bar']\n",
        "\n",
        "    state_adj['sp_bar'] = f_bar\n",
        "    helper.spolyval_adj(c, ts, state_adj)\n",
        "    x_bar -= f_bar\n",
        "    state_adj['x_bar'] = x_bar"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iG8pkjP8464i"
      },
      "source": [
        "The main part, run **spoly_interp(...)** with AAD + AIFT.\n",
        "\n",
        "  This is a modification of **spoly_interp()** that supports gradients via AAD + AIFT.\n",
        "    Note that all the adjoint steps can be automatically derived from the valuation steps by the AAD library and there are no explicit gradient manipulations.    \n",
        "    The original function **spoly_interp(...)** fits the stretched polynomial to **(ts,xs)** and evaluates it at **t**.\n",
        "    Here **pricing_helper** (via **pricing_helper.w_**) is defining the interpolation between knots. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "11CDo3fnuiw1"
      },
      "outputs": [],
      "source": [
        "def spoly_interp_aad(xs, ts, t, pricing_helper):\n",
        "    # Step 0. Initialize the state_adj\n",
        "    state_adj = init_state_adj(len(ts))\n",
        "\n",
        "    # Step 1. Update the weights w and extract the relevant gradients\n",
        "    pricing_helper.update(xs,ts)\n",
        "    dw_dx = pricing_helper.dw_dx_\n",
        "\n",
        "    # The original objective function\n",
        "    def obj_f(c, x, pricing_helper = pricing_helper):\n",
        "        return pricing_helper.spolyval(c, ts) - x\n",
        "    \n",
        "    # Step 2. Fit the objective function and extract the coefs c we fit\n",
        "    x0 = np.zeros_like(ts)\n",
        "    res = least_squares(lambda c: obj_f(c,xs), x0)\n",
        "    c_fit = res.x\n",
        "    \n",
        "    # Step 3. Calculate the value of spolyfit using the fitted coefs c_fit\n",
        "    v = pricing_helper.spolyval(c_fit, t)\n",
        "\n",
        "    # Gradient to coefs, known in the Newton method so no extra calcs here\n",
        "    dobj_dc = jacobian(obj_f, argnum = 0)(c_fit, xs)\n",
        "\n",
        "    # Adjoint for Step 3. I.e. propagate backwards until the call to the solver\n",
        "    pricing_helper.spolyval_adj(c_fit, t, state_adj)\n",
        "    c_bar = state_adj['c_bar']\n",
        "    \n",
        "    # Compute the correct adjoints of the objective function:\n",
        "    obj_f_bar = -np.linalg.lstsq(dobj_dc.T, c_bar, rcond = None)[0]\n",
        "    state_adj['f_bar'] = obj_f_bar\n",
        "   \n",
        "    # Adjoint for Step 2. Propagate through the objective function. Note that\n",
        "    # we do not have to compute dobj_dw unlike the Naive IFT approach\n",
        "    obj_f_adj(c_fit, ts, xs, pricing_helper, state_adj)\n",
        "    x_bar = state_adj['x_bar']\n",
        "    w_bar = state_adj['w_bar']\n",
        "    \n",
        "    # Adjoint for Step 1. Propagate through w=w(x)\n",
        "    x_bar += w_bar @ dw_dx\n",
        "\n",
        "    return v, x_bar\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6JUJ_ZBM464i"
      },
      "source": [
        "Calculate the gradients using AAD +AIFT and compare to the already computed gradients by bumping."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s9aukvhe464i",
        "outputId": "8552a6ef-c0d2-430c-d5be-c04da8ced588"
      },
      "outputs": [],
      "source": [
        "pricing_helper = PricingHelperAdj(w_to_use)\n",
        "v_aad, grad_aad = spoly_interp_aad(xs,ts,t,pricing_helper)\n",
        "print(f'value = {v_aad}')\n",
        "print(f'gradients by aad = {grad_aad}')\n",
        "print(f'gradients by bmp = {grad_bump}')\n",
        "print(f'difference in gradients = {grad_aad - grad_bump}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## The end"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "AIFT_paper_01.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "c75fd95ee6a8673db96eeaeea4fa8e27c3cb071aef74affedb213b23408cb297"
    },
    "kernelspec": {
      "display_name": "Python 3.8.8 64-bit ('base': venv)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
